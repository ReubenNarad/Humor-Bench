[
    {
        "display_name": "Qwen 2.5 72B",
        "explainer_model": "Qwen-Qwen2-5-72B-Instruct-Turbo",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.6112224448897795,
        "pass_rate_per_caption_all": 0.49514563106796117,
        "pass_rate_per_caption_some": 0.605177993527508,
        "total_cost": 1.1768771,
        "explainer_cost": 0.1892496,
        "avg_cost_per_row": 0.002358471142284569,
        "plot_color": "lightblue",
        "explainer_family": "open_source",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Qwen 2.5 72B",
        "gpqa_score": NaN,
        "arc_agi_score": NaN,
        "lmarena_elo_score": NaN
    },
    {
        "display_name": "Llama 4 Maverick",
        "explainer_model": "meta-llama-Llama-4-Maverick-17B-128E-Instruct-FP8",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.6673346693386774,
        "pass_rate_per_caption_all": 0.5566343042071198,
        "pass_rate_per_caption_some": 0.6699029126213594,
        "total_cost": 1.05301288,
        "explainer_cost": 0.07122788,
        "avg_cost_per_row": 0.00211024625250501,
        "plot_color": "lightblue",
        "explainer_family": "open_source",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Llama 4 Maverick",
        "gpqa_score": 0.698,
        "arc_agi_score": 0.044,
        "lmarena_elo_score": 1271.0
    },
    {
        "display_name": "gpt-4o",
        "explainer_model": "gpt-4o",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.7454909819639278,
        "pass_rate_per_caption_all": 0.6472491909385113,
        "pass_rate_per_caption_some": 0.7545846817691478,
        "total_cost": 2.022075,
        "explainer_cost": 0.972,
        "avg_cost_per_row": 0.004052254509018036,
        "plot_color": "#89e095",
        "explainer_family": "openai",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "gpt-4o",
        "gpqa_score": NaN,
        "arc_agi_score": 0.05,
        "lmarena_elo_score": 1407.0
    },
    {
        "display_name": "o4-mini",
        "explainer_model": "o4-mini",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.7735470941883767,
        "pass_rate_per_caption_all": 0.7022653721682848,
        "pass_rate_per_caption_some": 0.7912621359223301,
        "total_cost": 1.940822,
        "explainer_cost": 0.9388995000000001,
        "avg_cost_per_row": 0.003889422845691383,
        "plot_color": "#89e095",
        "explainer_family": "openai",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "o4-mini",
        "gpqa_score": 0.814,
        "arc_agi_score": NaN,
        "lmarena_elo_score": NaN
    },
    {
        "display_name": "Grok 3",
        "explainer_model": "grok-3-beta",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.7735470941883767,
        "pass_rate_per_caption_all": 0.6893203883495146,
        "pass_rate_per_caption_some": 0.7869471413160731,
        "total_cost": 2.517861,
        "explainer_cost": 1.457751,
        "avg_cost_per_row": 0.0050458136272545084,
        "plot_color": "#333333",
        "explainer_family": "XAI",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Grok 3",
        "gpqa_score": NaN,
        "arc_agi_score": NaN,
        "lmarena_elo_score": NaN
    },
    {
        "display_name": "o1",
        "explainer_model": "o1",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.7875751503006012,
        "pass_rate_per_caption_all": 0.7087378640776699,
        "pass_rate_per_caption_some": 0.7939590075512405,
        "total_cost": 20.72983,
        "explainer_cost": 19.717515,
        "avg_cost_per_row": 0.04154274549098196,
        "plot_color": "#89e095",
        "explainer_family": "openai",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "o1",
        "gpqa_score": 0.78,
        "arc_agi_score": 0.31,
        "lmarena_elo_score": 1350.0
    },
    {
        "display_name": "Claude Sonnet 4",
        "explainer_model": "claude-sonnet-4-20250514",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.7935871743486974,
        "pass_rate_per_caption_all": 0.7216828478964401,
        "pass_rate_per_caption_some": 0.796116504854369,
        "total_cost": 2.8726139999999996,
        "explainer_cost": 1.793949,
        "avg_cost_per_row": 0.005756741482965931,
        "plot_color": "#e3c771",
        "explainer_family": "anthropic",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Claude Sonnet 4",
        "gpqa_score": NaN,
        "arc_agi_score": NaN,
        "lmarena_elo_score": NaN
    },
    {
        "display_name": "DeepSeek R1",
        "explainer_model": "deepseek-ai-DeepSeek-R1",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.7975951903807615,
        "pass_rate_per_caption_all": 0.7087378640776699,
        "pass_rate_per_caption_some": 0.8042071197411002,
        "total_cost": 2.6854579999999997,
        "explainer_cost": 1.651933,
        "avg_cost_per_row": 0.0053816793587174346,
        "plot_color": "lightblue",
        "explainer_family": "open_source",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "DeepSeek R1",
        "gpqa_score": 0.715,
        "arc_agi_score": NaN,
        "lmarena_elo_score": NaN
    },
    {
        "display_name": "Claude 3.7 Sonnet",
        "explainer_model": "claude-3-7-sonnet-latest",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.8036072144288577,
        "pass_rate_per_caption_all": 0.7119741100323624,
        "pass_rate_per_caption_some": 0.8079827400215749,
        "total_cost": 2.6486275,
        "explainer_cost": 1.601415,
        "avg_cost_per_row": 0.005307870741482965,
        "plot_color": "#e3c771",
        "explainer_family": "anthropic",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Claude 3.7 Sonnet",
        "gpqa_score": 0.797,
        "arc_agi_score": 0.14,
        "lmarena_elo_score": 1293.0
    },
    {
        "display_name": "Gemini 2.5 pro",
        "explainer_model": "gemini-2-5-pro-preview-03-25",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.8076152304609219,
        "pass_rate_per_caption_all": 0.7216828478964401,
        "pass_rate_per_caption_some": 0.8058252427184465,
        "total_cost": 1.7213825,
        "explainer_cost": 0.714045,
        "avg_cost_per_row": 0.0034496643286573148,
        "plot_color": "#8055e6",
        "explainer_family": "google",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Gemini 2.5 pro",
        "gpqa_score": 0.802,
        "arc_agi_score": 0.125,
        "lmarena_elo_score": 1439.0
    },
    {
        "display_name": "Claude Opus 4",
        "explainer_model": "claude-opus-4-20250514",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.8489795918367347,
        "pass_rate_per_caption_all": 0.7922077922077922,
        "pass_rate_per_caption_some": 0.8609307359307358,
        "total_cost": 9.2960825,
        "explainer_cost": 8.25744,
        "avg_cost_per_row": 0.018629423847695392,
        "plot_color": "#e3c771",
        "explainer_family": "anthropic",
        "num_rows": 490,
        "num_captions": 308,
        "plot_label": "Claude Opus 4",
        "gpqa_score": NaN,
        "arc_agi_score": NaN,
        "lmarena_elo_score": NaN
    },
    {
        "display_name": "o3",
        "explainer_model": "o3",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.8657314629258517,
        "pass_rate_per_caption_all": 0.8122977346278317,
        "pass_rate_per_caption_some": 0.8748651564185546,
        "total_cost": 2.374133,
        "explainer_cost": 1.334458,
        "avg_cost_per_row": 0.004757781563126252,
        "plot_color": "#89e095",
        "explainer_family": "openai",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "o3",
        "gpqa_score": 0.833,
        "arc_agi_score": 0.757,
        "lmarena_elo_score": 1413.0
    },
    {
        "display_name": "Grok 4",
        "explainer_model": "grok-4-0709",
        "autograder_model": "gpt-4o",
        "pass_rate_per_row": 0.87374749498998,
        "pass_rate_per_caption_all": 0.8155339805825242,
        "pass_rate_per_caption_some": 0.8851132686084142,
        "total_cost": 2.066532,
        "explainer_cost": 1.0851570000000001,
        "avg_cost_per_row": 0.004141346693386774,
        "plot_color": "#333333",
        "explainer_family": "XAI",
        "num_rows": 499,
        "num_captions": 309,
        "plot_label": "Grok 4",
        "gpqa_score": NaN,
        "arc_agi_score": 0.66,
        "lmarena_elo_score": NaN
    }
]