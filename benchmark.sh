# python main_benchmark.py \
    # --explainer-model "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" \
    # --autograder-model "gpt-4o" \
    # --run-name "llama4_maverick_explainer_vs_gpt4o_grader"

# python main_benchmark.py \
#     --explainer-model "Qwen/Qwen2.5-72B-Instruct-Turbo" \
#     --autograder-model "gpt-4o" \
#     --run-name "qwen_explainer_vs_gpt4o_grader"

# python main_benchmark.py \
#     --explainer-model "o1" \
#     --autograder-model "gpt-4o" \
#     --run-name "o1_explainer_vs_gpt4o_grader" \
#     --n-workers 30 


# python main_benchmark.py \
#     --explainer-model "claude-3-7-sonnet-latest" \
#     --autograder-model "gpt-4o" \
#     --thinking-budget 4096 \
#     --run-name "claude_thinking_budget_4096"\
#     --n-workers 5

# python main_benchmark.py \
#     --explainer-model "grok-3-beta" \
#     --autograder-model "gpt-4o" \
#     --run-name "grok_3_beta" \
#     --n-workers 5 \


